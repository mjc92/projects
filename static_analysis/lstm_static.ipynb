{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on TensorFlow-Examples by aymericdamien\n",
    "https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time \n",
    "import datetime\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from tensorflow.contrib import learn\n",
    "from sklearn import metrics\n",
    "from tensorflow.python.ops import rnn, rnn_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 100\n",
    "num_epochs = 40\n",
    "display_step = 100\n",
    "\n",
    "# Network parameters\n",
    "n_input = 94\n",
    "n_steps = 50 # one string is 300 chars long, 6 chars will be observed at each step\n",
    "n_hidden = 128\n",
    "n_classes = 2\n",
    "sequence_length = 300\n",
    "min_char = 33\n",
    "max_char = 126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\",[None,sequence_length,n_input]) # takes in [batch,300,1,94]\n",
    "y = tf.placeholder(\"float\",[None,n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {'out': tf.Variable(tf.random_normal([n_hidden,n_classes]),name=\"weights\")}\n",
    "biases = {'out': tf.Variable(tf.random_normal([n_classes]),name=\"biases\")}\n",
    "\n",
    "allow_soft_placement=True\n",
    "log_device_placement=True\n",
    "allow_growth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# File directory\n",
    "train_FILE = 'train.txt'\n",
    "test_FILE = 'test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "# import training and test data\n",
    "\n",
    "xy_train = np.loadtxt(train_FILE,unpack=True,dtype='int')\n",
    "xy_test = np.loadtxt(test_FILE,unpack=True,dtype='int')\n",
    "print(\"Data loaded!\")\n",
    "\n",
    "xy_train = xy_train.T\n",
    "xy_test = xy_test.T\n",
    "print \"Training data shape: \"+str(xy_train.shape)\n",
    "print \"Test data shape: \"+str(xy_test.shape)\n",
    "\n",
    "# get training and test sets\n",
    "x_train = xy_train[:,0:300]\n",
    "y_train = xy_train[:,300]\n",
    "x_test = xy_test[:,0:300]\n",
    "y_test = xy_test[:,300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use portion of data\n",
    "tr_idx = np.random.permutation(len(y_train))\n",
    "tr_idx = tr_idx[0:50000]\n",
    "x_train = x_train[tr_idx,:]\n",
    "y_train = y_train[tr_idx]\n",
    "\n",
    "t_idx = np.random.permutation(len(y_test))\n",
    "t_idx=t_idx[0:10000]\n",
    "x_test = x_test[t_idx,:]\n",
    "y_test = y_test[t_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change x to one-hot\n",
    "def embed_x(x,max_char,min_char):\n",
    "    m,n = x.shape\n",
    "    out = np.zeros((m*n,max_char-min_char+1)) # (batch*length,94)\n",
    "    x_reshape = np.reshape(x,(m*n)) # (batch_length,1)\n",
    "    out[xrange(m*n),x_reshape-min_char]=1\n",
    "    out=np.reshape(out,(m,n,-1))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change y to 2 classes\n",
    "def embed_y(y):\n",
    "    y = np.concatenate([1-y,y],axis=1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RNN model\n",
    "def RNN(x, weights, biases,visualize=False):\n",
    "    with tf.device('/gpu:0'):\n",
    "        # Prepare data shape to match `rnn` function requirements\n",
    "        # Current data input shape: (batch_size, n_steps, n_input)\n",
    "        # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "        # Permuting batch_size and n_steps\n",
    "        print 'Permuting batch size and number of steps...'\n",
    "        x = tf.transpose(x, [1, 0, 2])\n",
    "        # Reshaping to (n_steps*batch_size, n_input)\n",
    "        print 'Reshaping to (n_steps * batch_size, n_input)...'\n",
    "        x = tf.reshape(x, [-1, n_input])\n",
    "        # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "        print 'Splitting to get a list of n_step tensors of shape (batch_size, n_input)...'\n",
    "        x = tf.split(0, sequence_length, x)\n",
    "        # x now is a list of 300 matrices, each with batch * 94\n",
    "        # Define a lstm cell with tensorflow\n",
    "        lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0,state_is_tuple=True)\n",
    "        print lstm_cell\n",
    "\n",
    "        # Get lstm cell output\n",
    "        outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)\n",
    "        #print \"Outputs of lstm:\"+str(outputs)\n",
    "        # output is 300 tensors of <tf.Tensor 'RNN/BasicLSTMCell_[number]/mul_2:0' shape=(?, 128) dtype=float32>\n",
    "        #print \"States:\"+str(states)\n",
    "        # a length T list of outputs (one for each input)\n",
    "\n",
    "        # states take form of c= c=<tf.Tensor 'RNN/BasicLSTMCell_299/add_2:0' shape=(?, 128) dtype=float32>, \n",
    "        # h=<tf.Tensor 'RNN/BasicLSTMCell_299/mul_2:0' shape=(?, 128) dtype=float32>\n",
    "        # only the final state\n",
    "        # Linear activation, using rnn inner loop last output\n",
    "        out = tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "        if visualize:\n",
    "            return out,outputs\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred, vis = RNN(x, weights, biases, visualize=True)\n",
    "# pred: Tensor(\"add:0\", shape=(?, 2), dtype=float32, device=/device:GPU:0)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create saver\n",
    "saver = tf.train.Saver()\n",
    "# set options\n",
    "gpu_options = tf.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction=0.333)\n",
    "config = tf.ConfigProto(log_device_placement=True, allow_soft_placement=True,\n",
    "                        gpu_options=gpu_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN!\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_batches = len(y_train)/batch_size\n",
    "steps=1\n",
    "for i in xrange(num_epochs):\n",
    "    tr_idx = np.random.permutation(len(y_train))\n",
    "    x_train = x_train[tr_idx,:]\n",
    "    y_train = y_train[tr_idx]\n",
    "    \n",
    "    for j in xrange(num_batches):\n",
    "        batch_x = x_train[j*batch_size:(j+1)*batch_size]\n",
    "        batch_y = y_train[j*batch_size:(j+1)*batch_size]\n",
    "        batch_x = embed_x(batch_x,max_char,min_char)\n",
    "        batch_y = embed_y(np.reshape(batch_y,(batch_y.shape[0],1)))\n",
    "        sess.run(optimizer, feed_dict = {x:batch_x,y:batch_y})\n",
    "        if (steps) % display_step ==0:\n",
    "            acc = sess.run(accuracy, feed_dict={x:batch_x,y:batch_y})\n",
    "            loss = sess.run(cost,feed_dict={x:batch_x,y:batch_y})\n",
    "            print \"Iter \" + str(steps) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc)\n",
    "        steps+=1\n",
    "    print \"End of Epoch %d........\\n\" %(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Optimization Finished! Saving variables...\"\n",
    "save_path = saver.save(sess,\"model.ckpt\")\n",
    "print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver.restore(sess,\"model.ckpt\")\n",
    "print \"Model restored\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy for other images\n",
    "test_len = 128\n",
    "#test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "#test_label = mnist.test.labels[:test_len]\n",
    "original_x = x_test # version without embedding\n",
    "x_test_embed = embed_x(x_test, max_char,min_char)\n",
    "y_test_embed = embed_y(np.reshape(y_test,(y_test.shape[0],1)))\n",
    "print \"Testing Accuracy:\", \\\n",
    "    sess.run(accuracy, feed_dict={x: x_test_embed, y: y_test_embed})\n",
    "test_pred=sess.run(pred, feed_dict={x: x_test_embed, y: y_test_embed})\n",
    "#print original_x[0]\n",
    "#        sess.run(accuracy, feed_dict={x: test_data, y: test_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pred_val=np.argmax(test_pred,1)\n",
    "auc = metrics.roc_auc_score(test_pred_val,y_test)\n",
    "print \"Testing AUC: %1.4f\" %auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer=sess.run(vis, feed_dict={x: x_test_embed, y: y_test_embed})\n",
    "layer=np.asarray(layer)\n",
    "print layer.shape\n",
    "layer= np.transpose(layer,[1,2,0])\n",
    "print layer.shape\n",
    "print layer[0].shape\n",
    "# layer has shape of [num_samples(10000), num_steps(300), num_filters(128)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in xrange(10):        \n",
    "    a = original_x[i]\n",
    "    b = layer[i]\n",
    "    np.savetxt('test_sample_'+str(i)+'.txt',a,delimiter=',',fmt=\"%d\")\n",
    "    np.savetxt('test_sample_filter_'+str(i)+'.txt',b,delimiter=',',fmt='%1.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

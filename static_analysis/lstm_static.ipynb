{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on TensorFlow-Examples by aymericdamien\n",
    "https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time \n",
    "import datetime\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from tensorflow.contrib import learn\n",
    "from sklearn import metrics\n",
    "from tensorflow.python.ops import rnn, rnn_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_iters = 100000\n",
    "batch_size = 100\n",
    "num_epochs = 1\n",
    "display_step = 100\n",
    "\n",
    "# Network parameters\n",
    "n_input = 94\n",
    "n_steps = 50 # one string is 300 chars long, 6 chars will be observed at each step\n",
    "n_hidden = 128\n",
    "n_classes = 2\n",
    "sequence_length = 300\n",
    "min_char = 33\n",
    "max_char = 126\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\",[None,sequence_length,n_input]) # takes in [batch,300,1,94]\n",
    "y = tf.placeholder(\"float\",[None,n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {'out': tf.Variable(tf.random_normal([n_hidden,n_classes]))}\n",
    "biases = {'out': tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "\"\"\"\n",
    "sequence_length=300\n",
    "num_classes=2\n",
    "\n",
    "vocab_size=100 # default\n",
    "num_filters=256\n",
    "l2_reg_lambda=0.0\n",
    "\n",
    "batch_size=100\n",
    "num_epochs=150\n",
    "evaluate_every=1000\n",
    "checkpoint_every=1000\n",
    "\"\"\"\n",
    "allow_soft_placement=True\n",
    "log_device_placement=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# File directory\n",
    "train_FILE = 'train.txt'\n",
    "test_FILE = 'test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "# import training and test data\n",
    "\n",
    "xy_train = np.loadtxt(train_FILE,unpack=True,dtype='int')\n",
    "xy_test = np.loadtxt(test_FILE,unpack=True,dtype='int')\n",
    "print(\"Data loaded!\")\n",
    "\n",
    "xy_train = xy_train.T\n",
    "xy_test = xy_test.T\n",
    "print \"Training data shape: \"+str(xy_train.shape)\n",
    "print \"Test data shape: \"+str(xy_test.shape)\n",
    "\n",
    "# get training and test sets\n",
    "x_train = xy_train[:,0:300]\n",
    "y_train = xy_train[:,300]\n",
    "x_test = xy_test[:,0:300]\n",
    "y_test = xy_test[:,300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use portion of data\n",
    "tr_idx = np.random.permutation(len(y_train))\n",
    "tr_idx = tr_idx[0:50000]\n",
    "x_train = x_train[tr_idx,:]\n",
    "y_train = y_train[tr_idx]\n",
    "\n",
    "t_idx = np.random.permutation(len(y_test))\n",
    "t_idx=t_idx[0:10000]\n",
    "x_test = x_test[t_idx,:]\n",
    "y_test = y_test[t_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change x to one-hot\n",
    "def embed_x(x,max_char,min_char):\n",
    "    m,n = x.shape\n",
    "    out = np.zeros((m*n,max_char-min_char+1)) # (batch*length,94)\n",
    "    x_reshape = np.reshape(x,(m*n)) # (batch_length,1)\n",
    "    out[xrange(m*n),x_reshape-min_char]=1\n",
    "    out=np.reshape(out,(m,n,-1))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change y to 2 classes\n",
    "def embed_y(y):\n",
    "    y = np.concatenate([1-y,y],axis=1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "    with tf.device('/gpu:0'):\n",
    "        # Prepare data shape to match `rnn` function requirements\n",
    "        # Current data input shape: (batch_size, n_steps, n_input)\n",
    "        # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "        # Permuting batch_size and n_steps\n",
    "        print 'Permuting batch size and number of steps...'\n",
    "        x = tf.transpose(x, [1, 0, 2])\n",
    "        # Reshaping to (n_steps*batch_size, n_input)\n",
    "        print 'Reshaping to (n_steps * batch_size, n_input)...'\n",
    "        x = tf.reshape(x, [-1, n_input])\n",
    "        # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "        print 'Splitting to get a list of n_step tensors of shape (batch_size, n_input)...'\n",
    "        x = tf.split(0, sequence_length, x)\n",
    "\n",
    "        # Define a lstm cell with tensorflow\n",
    "        lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0,state_is_tuple=True)\n",
    "        print lstm_cell\n",
    "\n",
    "        # Get lstm cell output\n",
    "        outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "        # Linear activation, using rnn inner loop last output\n",
    "        return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "pred = RNN(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create saver\n",
    "saver = tf.train.Saver()\n",
    "# Launch the graph\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True,gpu_options=gpu_options)) as sess:\n",
    "    sess.run(init)\n",
    "    # Keep training until reach max iterations\n",
    "    num_batches=len(y_train)/batch_size\n",
    "    steps=1\n",
    "    for i in xrange(num_epochs):\n",
    "        # shuffle data before dividing into batches\n",
    "        tr_idx=np.random.permutation(len(y_train))\n",
    "        x_train=x_train[tr_idx,:]\n",
    "        y_train=y_train[tr_idx]\n",
    "\n",
    "        for j in xrange(num_batches):\n",
    "            batch_x = x_train[j*batch_size:(j+1)*batch_size]\n",
    "            batch_y = y_train[j*batch_size:(j+1)*batch_size]\n",
    "            # embed x and y\n",
    "            batch_x = embed_x(batch_x,max_char,min_char)\n",
    "            batch_y = embed_y(np.reshape(batch_y,(batch_y.shape[0],1)))\n",
    "    #        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Reshape data to get 28 seq of 28 elements\n",
    "    #        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "            # batch_x: [100, 300, 94]\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "            if (steps) % display_step == 0:\n",
    "                # Calculate batch accuracy\n",
    "                acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "                # Calculate batch loss\n",
    "                loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            \tprint \"Iter \" + str(steps) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc)\n",
    "            steps+=1\n",
    "        print \"End of %dth epoch............\\n\"%(i+1)\n",
    "    print \"Optimization Finished! Saving variables...\"\n",
    "    #save_path = saver.save(sess,\"/tmp/\"+\"model_\"+str(time.time())+\".ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    #test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "    #test_label = mnist.test.labels[:test_len]\n",
    "    x_test = embed_x(x_test, max_char,min_char)\n",
    "    y_test = embed_y(np.reshape(y_test,(y_test.shape[0],1)))\n",
    "\n",
    "    print \"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: x_test, y: y_test})\n",
    "#        sess.run(accuracy, feed_dict={x: test_data, y: test_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.path.exists('saves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
